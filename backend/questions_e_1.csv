Question:問題文,Options[0]:正解選択肢,Options[1]:不正解選択肢1,Options[2]:不正解選択肢2,Options[3]:不正解選択肢3,Supplement:捕捉情報,Difficulty:難易度
"非線形な分離に不適切なカーネルはどれか？","線形カーネル","RBFカーネル","多項式カーネル","シグモイドカーネル","線形カーネルでは線形分離しかできない",1
"固有値と固有ベクトルを求めるための分解はどれか？","固有値分解","特異値分解","QR分解","LU分解","固有値分解は行列の固有値と固有ベクトルを求める方法です。",1
"次のうち、確率密度関数を持たないものはどれか？","確率質量関数","ガウス分布","t分布","ベルヌーイ分布","確率質量関数は離散型の分布で、確率密度関数を持ちません。",1
"次元圧縮において、主成分分析でよく使用される手法はどれか？","主成分分析","k-meansクラスタリング","線形回帰","ロジスティック回帰","主成分分析（PCA）は次元圧縮のために使用される手法です。",1
"ナイーブベイズ分類器の主要な仮定は何か？","特徴の独立性","特徴の従属性","線形分離可能性","非線形分離可能性","ナイーブベイズ分類器は、すべての特徴が互いに独立であると仮定します。",1
"ニューラルネットワークの活性化関数の一つであり、勾配消失問題を軽減するために使用されるものはどれか？","ReLU","シグモイド関数","ソフトマックス関数","ハイパボリックタンジェント関数","ReLU（Rectified Linear Unit）は勾配消失問題を軽減するために使用されます。",1
"次のうち、バギングの一種であり、多数の決定木を使用して予測を行う手法はどれか？","Random Forest","アンサンブル","ブースティング","k-meansクラスタリング","Random Forestはバギングの一種であり、多数の決定木を使用して予測を行います。",2
"深層学習モデルのトレーニングにおいて、学習率を動的に調整するアルゴリズムの一つはどれか？","Adam","SGD","モメンタム","Nesterov Accelerated Gradient","Adamは学習率を動的に調整するアルゴリズムの一つです。",2
"確率モデルにおけるパラメータ推定において、最も一般的に使用される手法はどれか？","最尤推定","最小二乗法","ベイズ推定","MAP推定","最尤推定は確率モデルにおけるパラメータ推定の最も一般的な手法です。",1
"次のうち、教師なし学習の手法はどれか？","k-meansクラスタリング","線形回帰","ロジスティック回帰","サポートベクターマシン","k-meansクラスタリングは教師なし学習の手法です。",1
"深層学習におけるドロップアウトの目的は何か？","過学習の防止","計算コストの削減","モデルの拡張","データの前処理","ドロップアウトは過学習を防止するための技術です。",1
"次のうち、勾配消失問題を緩和するために設計された活性化関数はどれか？","ReLU","シグモイド関数","ソフトマックス関数","線形関数","ReLU（Rectified Linear Unit）は勾配消失問題を緩和するために設計されました。",1
"RNNの中でも、長期依存関係を捉えるために設計されたものはどれか？","LSTM","単純RNN","GRU","トランスフォーマー","LSTM（Long Short-Term Memory）は長期依存関係を捉えるために設計されました。",1
"次のうち、決定木のアンサンブル学習の一種で、過学習を防ぐためにランダムな特徴量の選択を行う手法はどれか？","ランダムフォレスト","ブースティング","アダブースト","バギング","ランダムフォレストは過学習を防ぐためにランダムな特徴量の選択を行います。",2
"強化学習において、エージェントが環境から得た報酬に基づいて行動を学習するアルゴリズムはどれか？","Q学習","K近傍法","主成分分析","ロジスティック回帰","Q学習は強化学習のアルゴリズムです。",2
"次のうち、自己教師あり学習の一種として使用される手法はどれか？","コントラスト学習","サポートベクターマシン","決定木","ランダムフォレスト","コントラスト学習は自己教師あり学習の一種です。",3
"次のうち、確率分布のエントロピーを測定するための尺度はどれか？","エントロピー","自己情報量","相互情報量","クロスエントロピー","エントロピーは確率分布の不確実性を測定するための尺度です。",1
"パターン認識において、k近傍法の主な利点は何か？","単純な実装","高い計算効率","低いメモリ使用量","非線形分離可能性の処理","k近傍法は単純に実装できる点が主な利点です。",1
"次のうち、データセットの次元削減に使用される手法はどれか？","主成分分析","決定木","ランダムフォレスト","ロジスティック回帰","主成分分析（PCA）は次元削減に使用される手法です。",1
"ニューラルネットワークのトレーニングにおいて、学習率を動的に調整するアルゴリズムはどれか？","RMSprop","SGD","モメンタム","最急降下法","RMSpropは学習率を動的に調整するアルゴリズムです。",2
"次のうち、相互情報量を利用して特徴選択を行う手法はどれか？","ミュー情報","カイ二乗検定","線形回帰","主成分分析","ミュー情報は相互情報量を利用して特徴選択を行う手法です。",2
"次のうち、時系列データに適したモデルはどれか？","RNN","ロジスティック回帰","主成分分析","決定木","RNN（リカレントニューラルネットワーク）は時系列データに適したモデルです。",1
"グリッドサーチで最適化されるハイパーパラメータはどれか？","学習率","データセットの大きさ","活性化関数","最急降下法の更新式","グリッドサーチは学習率などのハイパーパラメータを最適化します。",2
"次のうち、画像データの前処理としてよく使用される手法はどれか？","正規化","標準化","欠損値補完","交差検証","画像データの前処理には正規化がよく使用されます。",2
"次のうち、勾配ブースティングアルゴリズムの一種はどれか？","XGBoost","ランダムフォレスト","サポートベクターマシン","k-meansクラスタリング","XGBoostは勾配ブースティングの一種です。",2
"強化学習において、エージェントが環境から得た報酬に基づいて行動を学習するアルゴリズムはどれか？","Q学習","K近傍法","主成分分析","ロジスティック回帰","Q学習は強化学習のアルゴリズムです。",2
"ニューラルネットワークのトレーニングにおける正則化手法はどれか？","L2正則化","最急降下法","クロスエントロピー","ロジスティック回帰","L2正則化は正則化手法です。",1
"データの欠損値補完に使用される手法はどれか？","k近傍法","線形回帰","主成分分析","ランダムフォレスト","k近傍法はデータの欠損値補完に使用されます。",1
"次のうち、ベイズ推定で使われる確率分布はどれか？","事前分布","ガウス分布","多項分布","正規分布","ベイズ推定では事前分布を用います。",1
"次のうち、ニューラルネットワークの層の重みを更新するためのアルゴリズムはどれか？","誤差逆伝播法","最急降下法","モメンタム","RMSprop","誤差逆伝播法は層の重みを更新するために使用されます。",3
"Batch Normalizationの主な目的はどれか？","学習を安定化し、収束を早める","モデルのサイズを小さくする","データの前処理を簡略化","過学習を促進する","Batch Normは学習の安定化と収束の高速化に寄与します。",1
"アンサンブル学習の一種で、弱学習器を連結して強力な学習器を作る手法はどれか？","ブースティング","バギング","スタッキング","クロスバリデーション","ブースティングは弱学習器を連結して性能を高めます。",1
"次のうち、確率的勾配降下法の一種で、過去の勾配を利用して更新を行うアルゴリズムはどれか？","モメンタム","SGD","最急降下法","Adam","モメンタムは過去の勾配を利用して更新を行います。",3
"次のうち、自己組織化マップ（SOM）の主な用途は何か？","次元削減と視覚化","分類","クラスタリング","予測","SOMは次元削減と視覚化に使用されます。",3
"次のうち、ニューラルネットワークのトレーニングにおいて、過学習を防ぐために使われる手法はどれか？","ドロップアウト","活性化関数の変更","データの標準化","データの正規化","ドロップアウトは過学習を防ぐために使用されます。",2
"RNNの一種であり、勾配消失問題を軽減するために設計されたものはどれか？","GRU","LSTM","単純RNN","トランスフォーマー","GRUは勾配消失問題を軽減するために設計されました。",2
"ニューラルネットワークのトレーニングにおいて、過学習を防ぐために使われる手法はどれか？","ドロップアウト","活性化関数の変更","データの標準化","データの正規化","ドロップアウトは過学習を防ぐために使用されます。",2
"ニューラルネットワークのトレーニングにおいて、学習率を動的に調整するアルゴリズムの一つはどれか？","RMSprop","SGD","モメンタム","最急降下法","RMSpropは学習率を動的に調整するアルゴリズムです。",2
"パターン認識において、k近傍法の主な利点は何か？","単純な実装","高い計算効率","低いメモリ使用量","非線形分離可能性の処理","k近傍法は単純に実装できる点が主な利点です。",1
"確率モデルにおけるパラメータ推定において、最も一般的に使用される手法はどれか？","最尤推定","最小二乗法","ベイズ推定","MAP推定","最尤推定は確率モデルにおけるパラメータ推定の最も一般的な手法です。",1
"自己教師あり学習の一種として使用される手法はどれか？","コントラスト学習","サポートベクターマシン","決定木","ランダムフォレスト","コントラスト学習は自己教師あり学習の一種です。",3
"次のうち、ガウス分布の平均の推定において使われる手法はどれか？","最尤推定","最小二乗法","クロスエントロピー","主成分分析","最尤推定はガウス分布の平均の推定に使用されます。",1
"次のうち、RNNの一種であり、勾配消失問題を軽減するために設計されたものはどれか？","GRU","LSTM","単純RNN","トランスフォーマー","GRUは勾配消失問題を軽減するために設計されました。",2
"決定木で使用される不純度指標はどれか？","Gini係数","エントロピー","平均二乗誤差","コサイン距離","決定木ではGini係数やエントロピーが使われます。",1
"主成分分析で次元削減する際に最大化するものはどれか？","データの分散","データの相関","データの平均","データのエントロピー","主成分分析ではデータの分散を最大化します。",1
"k-meansクラスタリングでクラスタ数を決定する際に用いる手法はどれか？","エルボー法","シルエット分析","主成分分析","ヒエラルキー法","エルボー法は適切なクラスタ数を決める際に用います。",1
"過剰適合を防ぐための手法はどれか？","正則化","データの増加","学習率の増加","バッチサイズの減少","正則化は過剰適合を防ぐ方法の一つです。",1
"交差検証でテストデータとして使用されないのはどれか？","訓練データ","検証データ","テストデータ","全データ","交差検証では訓練データと検証データを用います。",1
"次のうち、データセットのバイアスを計測するために使用される手法はどれか？","交差エントロピー","KLダイバージェンス","ロジスティック回帰","主成分分析","KLダイバージェンスはデータセットのバイアスを計測するために使用されます。",2
"次のうち、ニューラルネットワークのトレーニングにおけるパラメータの初期化戦略はどれか？","Xavier法","SGD","RMSprop","Adam","Xavier法はパラメータの初期化戦略です。",3
"確率的勾配降下法（SGD）の特徴はどれか？","ミニバッチを使用して学習する","全データを使用して勾配を計算する","勾配を上昇させる方向に更新する","学習率を自動で調整する","SGDはミニバッチを用いて学習します。",1
"モメンタムを利用した最適化手法の利点はどれか？","収束を加速できる","計算コストを削減","過学習を防止","パラメータの初期値に依存しない","モメンタムは収束を加速する効果があります。",1
"AdaGradの特徴はどれか？","学習率を各パラメータごとに調整する","勾配の方向を逆転させる","バッチ正規化を行う","データの拡張を自動化する","AdaGradは各パラメータの学習率を調整します。",1
"Xavierの初期化が適用されるのはどのような場合か？","活性化関数が線形またはtanhの場合","ReLU関数を使用する場合","シグモイド関数を使用する場合","重みがすべて同じ値の場合","Xavier初期化は線形・tanh関数に適しています。",1
"次のうち、混合ガウス分布のパラメータ推定に使われるアルゴリズムはどれか？","EMアルゴリズム","最急降下法","SGD","モメンタム","EMアルゴリズムは混合ガウス分布のパラメータ推定に使用されます。",1
"次のうち、ニューラルネットワークのトレーニングにおける正則化手法はどれか？","L2正則化","最急降下法","クロスエントロピー","ロジスティック回帰","L2正則化は正則化手法です。",3
"自己教師あり学習で特徴的な手法はどれか？","データからラベルを自動生成する","大量の手作業でのラベル付け","モデルのアンサンブル化","ハイパーパラメータの自動調整","自己教師あり学習はデータからラベルを生成します。",1
"Active Learningの主な目的はどれか？","効率的なデータ選択によるラベル付けコストの削減","モデルの構造自動化","パラメータの自動最適化","データの拡張","Active Learningは効率的なデータ選択を行います。",1
"メタ学習が目指すものはどれか？","新しいタスクへの迅速な適応","データセットの拡大","モデルの簡素化","計算コストの削減","メタ学習は新しいタスクへの迅速な適応を目指します。",1
"次のうち、データの欠損値補完に使用される手法はどれか？","k近傍法","線形回帰","主成分分析","ランダムフォレスト","k近傍法はデータの欠損値補完に使用されます。",3
"次のうち、サポートベクターマシンにおけるカーネル関数として適切なものはどれか？","RBFカーネル","線形カーネル","多項式カーネル","シグモイドカーネル","RBFカーネルはSVMでよく使用されるカーネル関数です。",3
"決定木のノード分割に使用される基準はどれか？","Gini係数","相互情報量","クロスエントロピー","相関係数","Gini係数は決定木のノード分割に使用される基準です。",1
"画像認識において一般的に使用される畳み込みニューラルネットワークの構造はどれか？","ResNet","LSTM","GRU","トランスフォーマー","ResNetは画像認識に一般的に使用される畳み込みニューラルネットワークの構造です。",1
"画像データの前処理としてよく使用される正規化手法はどれか？","Batch Normalization","標準化","欠損値補完","交差検証","Batch Normalizationは画像データの前処理としてよく使用されます。",1
"ディープラーニングにおけるデータ拡張手法の一つはどれか？","Random Flip","正則化","クロスエントロピー","主成分分析","Random Flipはデータ拡張手法の一つです。",2
"自己組織化マップ（SOM）の主な用途は何か？","次元削減と視覚化","分類","クラスタリング","予測","自己組織化マップは次元削減と視覚化に使用されます。",2
"ニューラルネットワークのトレーニングにおいて、パラメータの初期化戦略として使用されるのはどれか？","Xavier法","SGD","RMSprop","Adam","Xavier法はパラメータの初期化戦略です。",1