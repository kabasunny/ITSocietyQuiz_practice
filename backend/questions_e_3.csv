Question:問題文,Options[0]:正解選択肢,Options[1]:不正解選択肢1,Options[2]:不正解選択肢2,Options[3]:不正解選択肢3,Supplement:捕捉情報,Difficulty:難易度
"行列の積ABにおいて、Aがm×n行列、Bがn×p行列であるとき、積ABの行列のサイズは？","m×p","n×n","m×n","p×n","行列の積のサイズは、Aの行数とBの列数になります。",1
"行列のランクとは？","一次独立な列ベクトルの最大個数","行列の要素の総和","行列の行列式の値","行列のサイズの積","ランクは行列の線形独立性を示す重要な指標です。",1
"テンソルとは？","多次元配列のデータ構造","スカラー量の別名","ベクトルの一種","行列の行列式","テンソルは多次元データを表現するのに適しています。",1
"アダマール積が定義されるためには、二つの行列の何が一致する必要がある？","行列のサイズ","行列のランク","行列式","固有値","アダマール積は要素ごとの積を計算するため、行列のサイズが一致する必要があります。",1
"行列Aの固有ベクトルxとは？","Ax = λx を満たす非零ベクトルx","Aの逆行列を求めるためのベクトル","Aの転置行列を求めるためのベクトル","Aの行列式を計算するためのベクトル","固有ベクトルは行列の変換に対して方向が変わらない特別なベクトルです。",1
"行列を対角化する目的は？","行列のべき乗計算を容易にするため","行列の要素を全て0にするため","行列のサイズを小さくするため","行列のランクを上げるため","対角化により、行列のべき乗計算などが容易になります。",1
"特異値分解とは？","任意の行列を特異値と特異ベクトルを用いて分解すること","正方行列のみを分解すること","行列を三角行列に分解すること","行列を複数の行列の積に分解すること","特異値分解は一般の行列に対して適用可能です。",1
"確率変数とは？","試行の結果に応じて値が決まる変数","常に一定の値をとる変数","試行の回数を表す変数","確率の値を表す変数","確率変数は試行の結果に依存して値が変化します。",1
"二つの事象AとBが独立であるとき、同時確率P(A∩B)は？","P(A)P(B)","P(A)+P(B)","P(A|B)","P(B|A)","独立な事象の同時確率は、それぞれの事象の確率の積で表されます。",1
"条件付き確率P(A|B)とは？","事象Bが起こった条件下での事象Aの確率","事象AとBが同時に起こる確率","事象Aが起こる確率","事象Bが起こる確率","条件付き確率は、ある事象が起こったという条件下での別の事象の確率を表します。",1
"確率質量関数が定義されるのは？","離散型確率変数","連続型確率変数","常に一定の値をとる確率変数","確率が定義されない変数","離散型確率変数は確率質量関数によって確率が定義されます。",1
"確率密度関数の全区間での積分値は？","1","0","無限大","定義されない","確率密度関数を全区間で積分すると1になります。",1
"ベルヌーイ試行とは？","結果が成功か失敗のどちらかになる試行","複数の結果があり得る試行","結果が数値で表される試行","結果が確率で表される試行","ベルヌーイ試行は成功か失敗の二つの結果のみを持つ試行です。",1
"二項分布のパラメータは？","試行回数と成功確率","平均と分散","歪度と尖度","最大値と最小値","二項分布は試行回数と成功確率によって特徴づけられます。",1
"ガウス分布の形状は？","釣り鐘型","U字型","L字型","逆U字型","ガウス分布は釣り鐘型の特徴的な形状をしています。",1
"中心極限定理とは？","独立な確率変数の和の分布がサンプルサイズを大きくするとガウス分布に近づく定理","確率変数の平均が常に一定の値に収束する定理","確率変数の分散が常に一定の値に収束する定理","確率変数の最大値が一定の値に収束する定理","中心極限定理は統計学において非常に重要な定理です。",1
"ベイズ則は、何を求めるために用いられる？","事後確率","事前確率","尤度","周辺確率","ベイズ則は事前確率と尤度から事後確率を求めるために用いられます。",1
"ナイーブベイズの「ナイーブ」とは何を意味する？","特徴量間に条件付き独立を仮定すること","特徴量を単純化すること","特徴量の数を減らすこと","特徴量の計算を簡略化すること","ナイーブベイズは特徴量間の条件付き独立を仮定するため「ナイーブ」と呼ばれます。",1
"平均二乗誤差は何を測る指標？","予測値と真値の差の二乗の平均","予測値と真値の差の絶対値の平均","予測値と真値の差の符号","予測値の分散","平均二乗誤差は回帰モデルの性能評価に用いられます。",1
"最尤推定とは？","尤度関数を最大にするパラメータを求めること","事後確率を最大にするパラメータを求めること","事前確率を最大にするパラメータを求めること","周辺確率を最大にするパラメータを求めること","最尤推定は観測データから最も尤もらしいパラメータを推定する方法です。",1
"自己情報量とは？","事象の起こりにくさを表す量","事象の重要性を表す量","事象の発生頻度を表す量","事象の因果関係を表す量","自己情報量は事象の確率の逆数の対数で表されます。",1
"相互情報量とは？","二つの確率変数の間の関連性を表す量","一つの確率変数の不確実性を表す量","二つの確率変数の和の不確実性を表す量","二つの確率変数の差の不確実性を表す量","相互情報量は二つの確率変数がどれだけ情報を共有しているかを表します。",1
"エントロピーとは？","確率変数の不確実性を表す量","確率変数の平均値を表す量","確率変数の最大値を表す量","確率変数の最小値を表す量","エントロピーは情報理論における重要な概念です。",1
"クロスエントロピーとは？","二つの確率分布間の差異を表す量","一つの確率分布の不確実性を表す量","二つの確率分布の和の不確実性を表す量","二つの確率分布の差の不確実性を表す量","クロスエントロピーは主に機械学習の損失関数として用いられます。",1
"KLダイバージェンスとは？","二つの確率分布の間の距離を表す指標","二つの確率分布の類似度を表す指標","一つの確率分布の平均値を表す指標","一つの確率分布の分散を表す指標","KLダイバージェンスは二つの確率分布の違いを測る尺度です。",1
"k近傍法において、kの値が大きいほどモデルの複雑さはどうなる？","低くなる","高くなる","変わらない","一定ではない","kの値が大きいほどモデルは単純になります。",1
"ユークリッド距離とは？","二点間の直線距離","二点間の経路距離","二点間の角度","二点間の面積","ユークリッド距離は最も一般的に用いられる距離尺度です。",1
"教師あり学習とは？","入力データと正解データを用いて学習する手法","入力データのみを用いて学習する手法","正解データのみを用いて学習する手法","データを用いずに学習する手法","教師あり学習はラベル付きデータを用いてモデルを学習します。",1
"Lasso回帰で用いられる正則化は？","L1正則化","L2正則化","L0正則化","正則化なし","Lasso回帰はL1正則化を用いてモデルのスパース性を高めます。",1
"過剰適合（オーバーフィッティング）とは？","訓練データに過度に適合し、未知のデータへの汎化性能が低い状態","訓練データに適合できず、未知のデータへの汎化性能も低い状態","訓練データにも未知のデータにも適合できる状態","データに全く適合できない状態","過剰適合はモデルの汎化性能を低下させます。",1
"ロジスティック回帰で用いられる関数は？","シグモイド関数","ステップ関数","線形関数","二次関数","ロジスティック回帰ではシグモイド関数を用いて確率を予測します。",1
"サポートベクターマシンにおいてマージン最大化の目的は？","汎化性能の向上","計算速度の向上","データ量の削減","特徴量の削減","マージン最大化により、SVMは高い汎化性能を実現します。",1
